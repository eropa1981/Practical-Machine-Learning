X<-as(A,"adjacencyMatrix")
areTheSame(as(X,"adjacencyList"),A)
names(G[10:12]+v("y","z"))
areTheSame(G[1:6],G-v(letters[7:12]))
areTheSame(G[1:6],G*v(letters[1:6]))
isPresent(u(2,4,5),G-u(2,4,5))
(I[1:4]+u(3,4))-d(2,4)
areTheSame(A[1:6]*v("b","d"),A[c(2,4)])
isPresent(r(1,2),X[10:12])
X[10:12]+d(1,2)
isPresent(u(1,2),X[10:12]+d(1,2))
isPresent(r(1,2),X[10:12]+d(1,2))
# Classes for graphs
isPresent(d(2,4),ag)
isPresent(u(2,4),ag)
isPresent(u(2,4,5),ag)
isPresent(d(2,4),gg)
isPresent(u(2,4),gg)
isPresent(u(2,4,5),gg)
isPresent(d(2,4),mg)
isPresent(u(2,4),mg)
isPresent(u(2,4,5),mg)
isPresent(d(2,4),sg)
isPresent(u(2,4),sg)
isPresent(u(2,4,5),sg)
areTheSame(ag,gg)
areTheSame(gg,mg)
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
52
4/52
0
12/52
2/51
.64
.64
mypdf
integrate(mypdf,0,1.6)
1.414214
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
library(rattle)
rattle()
library(rattle)
rattle()
install.packages("rattle")
q()
library("rattle", lib.loc="~/R/win-library/3.1")
install.packages("rattle")
library(rattle)
rattle()
install.packages("rattle", repos="http://rattle.togaware.com", type="source")
library(rattle)
rattle()
q()
data<-read.csv("file:///C:/Users/Eropa1981/Dropbox/didacticos/Clases Impartidas/2015/Programa de Especialización en BI-Modulo IV Minería de Datos/weather.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")
```
data<-read.csv("C:/Users/Eropa1981/Dropbox/didacticos/Clases Impartidas/2015/Programa de Especialización en BI-Modulo IV Minería de Datos/weather.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")
head(data)
view(data)
View(data)
hist(data$MaxTemp)
hist(data$MaxTemp,col="Darkred")
boxplot(data$MaxTemp)
boxplot(data$MaxTemp,col="Darkgreen")
summary(data)
summary(data$MaxTemp)
rep(1,100)
summary(data$MaxTemp)
range(data$MaxTemp)
?range
range[1]
range[,1]
max(data$MaxTemp)-min(data$MaxTemp)
numeros<-c(20,40,50,60,80)
numeros
mean(numeros)
var(numeros)
var(diff(numeros))
sd(numeros)
mad(numeros)
median(numeros)
install.packages("spam")
spam
library(kernlab)
data(spam)
head(spam)
View)head((spam))
View(head((spam))
View(head(spam))
str(spam)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
# Step-like pattern -> 4 categories
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
# Another way
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
summary(log(training))
hist(log(training$Superplasticizer))
qqnorm(training$Superplasticizer)
hist(log(training$Superplasticizer))
qqnorm(training$Superplasticizer)
hist(log(training$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProcess()
preProcess(training)
names(training)
grep(glob2rx("IL*"), names(training))
training2 <- training[, grep(glob2rx("IL*"), names(training))]
names(training2)
pp <- preProcess(training2,
method="pca",
thresh = 0.8) # buenísimo esto: pones tu objetivo de varianza explicada
pp
pp <- preProcess(training2,
method="pca",
thresh = 0.9) # buenísimo esto: pones tu objetivo de varianza explicada
pp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
print(C2)
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
rm(ls=list())
rm(ls=list())
install.packages("Rcmdr")
library(Rcmdr)
library(Rcmdr)
library(Rcmdr)
View(molten_students)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
fancyRpartPlot(model$finalModel)
install.packages("fancyRpartPlot")
fancyRpartPlot(model$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
fancyRpartPlot(model$finalModel)
install.packages("fancyRpartPlot")
RpartPlot(model$finalModel)
install.packages("rpart.plot")
Rpart.Plot(model$finalModel)
RpartPlot(model$finalModel)
Rpart.Plot(model$finalModel)
rpart.plot(model$finalModel)
rpartplot(model$finalModel)
plot(model$finalModel)
plot(finalModel)
plot(cartModel$finalModel)
rpart.plot(cartModel$finalModel)
fancyRpartPlot(cartModel$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
library(rpart)
library(ggplot2)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
library(rpart)
library(rpart)
library(ggplot2)
library(rattle)
fancyRpartPlot(cartModel$finalModel)
win.graph()
fancyRpartPlot(cartModel$finalModel)
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 => PS
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
olive
head(olive)
newdata = as.data.frame(t(colMeans(olive)))
head(newdata)
model<-train(Area ~ ., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
# Training Set Misclassification rate
missClass(trainSA$chd, predictTrain) # 0.2727273
# Test Set Misclassification rate
missClass(testSA$chd, predictTest) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
install.packages("randomForest")
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(rattle)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(randomForest)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
install.packages("AppliedPredictiveModeling")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
confusionMatrix(predRf, vowel.test$y)$overall[1]
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(adData) # 333 131
head(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
getwd()
setwd("C:/Users/Eropa1981/Documents")
getwd()
setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
getwd()
trainDB <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDB <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainCsv <- "./data/pml-training.csv"
testCsv  <- "./data/pml-testing.csv"
if (!file.exists("./inputs")) {
dir.create("./inputs")
}
if (!file.exists(trainCsv)) {
download.file(trainDB, destfile=trainCsv, method="curl")
}
if (!file.exists(testCsv)) {
download.file(testDB, destfile=testDB, method="curl")
}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
Dir<-setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
Dir
Dir<-setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
Dir
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "Dir/data/pml-training.csv"
testFile  <- "Dir/data/pml-testing.csv"
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
```{r}
Dir<-setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
Dir
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "Dir/data/pml-training.csv"
testFile  <- "Dir/data/pml-testing.csv"
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
download.file(trainUrl, destfile=trainFile, method="curl"
download.file(trainUrl, destfile=trainFile, method="curl")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "Dir/pml-training.csv"
testFile  <- "Dir/pml-testing.csv"
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
trainFile <- "training.csv"
testFile  <- "testing.csv"
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
download.file(trainUrl, destfile=trainFile, method="curl")
download.file(trainUrl, destfile=trainFile)
Dir<-setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
dir(Dir)
Dir<-setwd("C:/Users/Eropa1981/Desktop/MachineLearning")
dir(Dir)
